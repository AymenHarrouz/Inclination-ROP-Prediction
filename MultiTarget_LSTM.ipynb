{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cGla8Zi-DAPO"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "from sklearn.feature_selection import SelectKBest,chi2\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from keras.models import Sequential\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import LSTM\n",
        "from keras.preprocessing.sequence import TimeseriesGenerator\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.losses import MeanSquaredError\n",
        "from keras.losses import MeanAbsoluteError\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import InputLayer\n",
        "from keras.models import load_model\n",
        "from tensorflow import keras\n",
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        "\n",
        "from dateutil.relativedelta import relativedelta\n",
        "from datetime import datetime\n",
        "\n",
        "from statistics import mean\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "import keras_tuner as kt\n",
        "\n",
        "from keras.layers import concatenate\n",
        "\n",
        "from tensorflow.keras.layers import Input, Concatenate, Dense, Reshape\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras as ks\n",
        "\n",
        "from scipy.interpolate import interp1d\n",
        "from scipy.interpolate import CubicSpline\n",
        "from scipy.signal import savgol_filter\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Import Data\n",
        "# =============================================================================\n",
        "\n",
        "data = pd.read_csv('Norway-NA-15_$47$_9-F-9 A depth.csv')\n",
        "#data = data.iloc[1817:10000,:]\n",
        "data = data.iloc[1424:10080,:] #470 to 848 + 10"
      ],
      "metadata": {
        "id": "ut1C8HgCDmKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# NaN Values Count\n",
        "# =============================================================================\n",
        "'''\n",
        "Na=data.isna().sum(axis=0)\n",
        "NaPercent = Na*100/8183\n",
        "NaPercent.value_counts()\n",
        "count = NaPercent>95\n",
        "count.sum()\n",
        "'''"
      ],
      "metadata": {
        "id": "vsyoTxtoDpgj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Variance Count\n",
        "# =============================================================================\n",
        "'''\n",
        "var = data.var(axis=0)\n",
        "varmask = var > 0.1\n",
        "varcount = varmask.value_counts()\n",
        "'''"
      ],
      "metadata": {
        "id": "7b65ofNeDry2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Droping the Unwanted Columns\n",
        "# =============================================================================\n",
        "\n",
        "dataFiltered = data.drop(['MWD Magnetic Toolface dega',\n",
        "                          'IMP/ARC Attenuation Conductivity 40-in. at 2 MHz mS/m',\n",
        "                          'ARC Annular Pressure kPa',\n",
        "                          'MWD Collar RPM rpm',\n",
        "                          'IMP/ARC Non-BHcorr Phase-Shift Resistivity 28-in. at 2 MHz ohm.m',\n",
        "                          'IMP/ARC Phase-Shift Conductivity 40-in. at 2 MHz mS/m',\n",
        "                          'Annular Temperature degC',\n",
        "                          'IMP/ARC Non-BHcorr Phase-Shift Resistivity 40-in. at 2 MHz ohm.m',\n",
        "                          'ARC Gamma Ray (BH corrected) gAPI',\n",
        "                          'IMP/ARC Non-BHcorr Attenuation Resistivity 40-in. at 2 MHz ohm.m',\n",
        "                          'MWD Stick-Slip PKtoPK RPM rpm',\n",
        "                          'IMP/ARC Non-BHcorr Attenuation Resistivity 28-in. at 2 MHz ohm.m',\n",
        "                          'IMP/ARC Phase-Shift Conductivity 28-in. at 2 MHz mS/m',\n",
        "                          'MWD Total Shocks unitless',\n",
        "                          'ROPIH s/m',\n",
        "                          'HKLO kkgf',\n",
        "                          'DRET unitless',\n",
        "                          'Pump 1 Strokes unitless',\n",
        "                          'Pump 2 Strokes unitless',\n",
        "                          'Pump 3 Strokes unitless',\n",
        "                          'Total Strokes unitless',\n",
        "                          'Bit Depth m',\n",
        "                          'String weight (rot,avg) kkgf',\n",
        "                          'TOBO s',\n",
        "                          'HKLI kkgf',\n",
        "                          'Elapsed time in-slips s',\n",
        "                          'Pump 4 Strokes unitless',\n",
        "                          'Mud Density Out g/cm3',\n",
        "                          'Iso-butane (IC4) ppm',\n",
        "                          'Nor-butane (NC4) ppm',\n",
        "                          'Lag Depth (TVD) m',\n",
        "                          'Ethane (C2) ppm',\n",
        "                          'TMP In degC',\n",
        "                          'n-Penthane ppm',\n",
        "                          'Iso-pentane (IC5) ppm',\n",
        "                          'Gas (avg) %',\n",
        "                          'Propane (C3) ppm',\n",
        "                          'Temperature Out degC',\n",
        "                          'Methane (C1) ppm',\n",
        "                          'Unnamed: 0.1',\n",
        "                          'Unnamed: 0',\n",
        "                          'nameWellbore',\n",
        "                          'name',\n",
        "                          'Bit run number unitless',\n",
        "                          'Inverse ROP (5ft avg) s/m',\n",
        "                          'Inverse ROP s/m',\n",
        "                          'Rate of Penetration (5ft avg) m/h',\n",
        "                          'Rate of penetration m/h',\n",
        "\n",
        "                          'PowerUP Shock Rate 1/s',\n",
        "                          'EDRT unitless',\n",
        "                          'MWD Shock Risk unitless',\n",
        "                          'Bit run number unitless',\n",
        "                          'Pump 4 Stroke Rate 1/min',\n",
        "                          'Rig Mode unitless',\n",
        "                          'AJAM_MWD unitless',\n",
        "                          'BHFG unitless',\n",
        "                          'SHK3TM_RT min',\n",
        "                          'Mud Density In g/cm3.1',\n",
        "                          'IMWT g/cm3',\n",
        "                          'Mud Density In g/cm3',\n",
        "                          'SPN Sp_RigMode 2hz unitless',\n",
        "                          'Pump 2 Stroke Rate 1/min',\n",
        "                          'Pass Name unitless'],axis=1)"
      ],
      "metadata": {
        "id": "ZVGJXELtDuDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Data Imputation\n",
        "# =============================================================================\n",
        "\n",
        "dataImputed = dataFiltered.interpolate(method='linear', axis=0)\n",
        "dataImputed = dataImputed.fillna(method='backfill', axis=0)\n",
        "dataImputed = dataImputed.fillna(method='ffill', axis=0)"
      ],
      "metadata": {
        "id": "S64X-ENVD-F-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Index Set to Measured Depth\n",
        "# =============================================================================\n",
        "\n",
        "dataImputed = dataImputed.set_index('Measured Depth m')"
      ],
      "metadata": {
        "id": "l3lCwxJtEBD1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Data Resampling\n",
        "# =============================================================================\n",
        "\n",
        "DataResampled = dataImputed.reset_index()\n",
        "MD = DataResampled.iloc[:,0].values\n",
        "RestOfData = DataResampled.iloc[:,:].values\n",
        "\n",
        "desired_depth_step = 0.05\n",
        "min_depth = 500 #np.min(MD)\n",
        "max_depth = 845 #np.max(MD)\n",
        "new_depths = np.arange(min_depth, max_depth + desired_depth_step, desired_depth_step)\n",
        "new_depths = np.round(new_depths, decimals=2)\n",
        "\n",
        "num_measurements = 53\n",
        "\n",
        "new_measurement_data = []\n",
        "for i in range(num_measurements):\n",
        "    new_measurement_data.append(np.interp(new_depths, MD, RestOfData[:, i],\n",
        "                                          left=None, right=None, period=None))\n",
        "\n",
        "new_measurement_data = np.array(new_measurement_data).T\n",
        "\n",
        "\n",
        "\n",
        "new_measurement_data[:,0] = np.round(new_measurement_data[:, 0], decimals=2)\n",
        "\n",
        "Col = DataResampled.columns.tolist()\n",
        "\n",
        "DataResampled = pd.DataFrame(data=new_measurement_data,columns=Col)\n",
        "DataResampled.set_index('Measured Depth m',inplace=True)\n",
        "\n",
        "DataResampled = DataResampled[470:889] #reconsider this\n",
        "\n",
        "\n",
        "rolling_window = 10\n",
        "DataSmoothed = DataResampled.rolling(window=rolling_window, min_periods=1, center=True).mean()"
      ],
      "metadata": {
        "id": "3OStCiLSEHDA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Features and Targets\n",
        "# =============================================================================\n",
        "\n",
        "dataROP = DataSmoothed[500:844.01]\n",
        "\n",
        "Inclination = DataSmoothed['MWD Continuous Inclination dega']\n",
        "RateOfPenetration = dataROP['Rate of Penetration m/h']\n",
        "Inc = dataROP['MWD Continuous Inclination dega']\n",
        "\n",
        "Inclination = Inclination.to_frame()\n",
        "RateOfPenetration= RateOfPenetration.to_frame()\n",
        "Inc= Inc.to_frame()\n",
        "\n",
        "\n",
        "FeaturesROP = dataROP.drop(['Rate of Penetration m/h',\n",
        "                            'MWD Continuous Inclination dega'], axis=1)"
      ],
      "metadata": {
        "id": "vsECuEDkEIN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Inclination Data Resampling\n",
        "# =============================================================================\n",
        "\n",
        "InclinationData = Inclination.round({\"MWD Continuous Inclination dega\":2})\n",
        "\n",
        "InclinationData = InclinationData[470:889]"
      ],
      "metadata": {
        "id": "bBIU0bpQFMCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "#  Scaling\n",
        "# =============================================================================\n",
        "\n",
        "\n",
        "FeaturesROP = (FeaturesROP-FeaturesROP.min())/(\n",
        "    FeaturesROP.max()-FeaturesROP.min())"
      ],
      "metadata": {
        "id": "quVdG9oeFPBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Inclination Data Preparation\n",
        "# =============================================================================\n",
        "\n",
        "\n",
        "'''Creating the dataset (Forcasting --> Supervised Learning)'''\n",
        "\n",
        "\n",
        "LearningWindow = 100\n",
        "ForwardPrediction = 1\n",
        "\n",
        "def series_to_supervised (data, n_in, n_out, dropnan):\n",
        "\n",
        "    n_vars = 1 if type(data) is list else data.shape[1]\n",
        "    df = DataFrame(data)\n",
        "    cols, names = list(),list()\n",
        "    # input sequence (t-n,...,t-1)\n",
        "    for i in range (n_in,0,-1):\n",
        "        cols.append(df.shift(i))\n",
        "        names += [('var%d(t-%d)' % (j+1,i)) for j in range (n_vars)]\n",
        "    # output sequence (t,...,t+n)\n",
        "    for i in range (0,n_out):\n",
        "        cols.append(df.shift(-i))\n",
        "        if i==0:\n",
        "            names += [('var%d(t)' % (j+1)) for j in range (n_vars)]\n",
        "        else:\n",
        "            names += [('var%d(t+%d)' % (j+1,i)) for j in range (n_vars)]\n",
        "\n",
        "    # Put it togather\n",
        "    agg = concat(cols,axis=1)\n",
        "    agg.columns = names\n",
        "\n",
        "    #Drop rows aith NaN values\n",
        "    if dropnan:\n",
        "        agg.dropna(inplace=True)\n",
        "\n",
        "    return agg\n",
        "\n",
        "\n",
        "# Inclination Change\n",
        "#der = InclinationData.diff()\n",
        "#der = der.fillna(method='backfill', axis=0)\n",
        "\n",
        "XY = series_to_supervised(InclinationData,\n",
        "                          LearningWindow,\n",
        "                          ForwardPrediction,\n",
        "                          dropnan=True)\n",
        "XY = XY[500:844]\n",
        "\n",
        "X2, y2 = XY.iloc[:,:LearningWindow], XY.iloc[:,LearningWindow:]"
      ],
      "metadata": {
        "id": "1vc_-QoIFTog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Multi Target Data Preparation\n",
        "# =============================================================================\n",
        "\n",
        "X1= FeaturesROP\n",
        "y1= RateOfPenetration\n",
        "\n",
        "y = pd.concat([RateOfPenetration,Inc],axis=1)"
      ],
      "metadata": {
        "id": "0CjBYSbkFWlj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Exporting to Excel to be used in google colab\n",
        "# =============================================================================\n",
        "\n",
        "#X1\n",
        "file_name_X1 = 'X1.csv'\n",
        "X1.to_csv(file_name_X1)\n",
        "#y1\n",
        "file_name_y1 = 'y1.csv'\n",
        "y1.to_csv(file_name_y1)\n",
        "#X2\n",
        "file_name_X2 = 'X2.csv'\n",
        "X2.to_csv(file_name_X2)\n",
        "#y2\n",
        "file_name_y2 = 'y2.csv'\n",
        "y2.to_csv(file_name_y2)"
      ],
      "metadata": {
        "id": "qrmBcfRYFYvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Data Spliting\n",
        "# =============================================================================\n",
        "\n",
        "X1_train, y1_train = X1[500:779.99], y1[500:779.99]\n",
        "X1_val, y1_val = X1[780:819.99], y1[780:819.99]\n",
        "X1_test, y1_test = X1[820:844], y1[820:844]\n",
        "\n",
        "\n",
        "X2_train, y2_train = X2[500:779.99], y2[500:779.99]\n",
        "X2_val, y2_val = X2[780:819.99], y2[780:819.99]\n",
        "X2_test, y2_test = X2[820:844], y2[820:844]\n",
        "\n",
        "\n",
        "y_train,y_val,y_test = y[500:779.99],y[780:819.99],y[820:844]"
      ],
      "metadata": {
        "id": "UEEzR1P3FbBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Multi Target Model\n",
        "# =============================================================================\n",
        "\n",
        "drop=0.05\n",
        "\n",
        "modelMulti = Sequential ()\n",
        "\n",
        "modelMulti.add(Dense(1024, input_dim=50, activation='relu'))\n",
        "modelMulti.add(Dropout(drop))\n",
        "\n",
        "\n",
        "modelMulti.add(Dense(1024, activation='relu'))\n",
        "modelMulti.add(Dropout(drop))\n",
        "\n",
        "\n",
        "modelMulti.add(Dense(1, activation='linear'))\n",
        "\n",
        "#creating a checkpoint when the best validation loss is found\n",
        "cpMulti = ModelCheckpoint('modelMulti/', save_best_only=True)\n",
        "\n",
        "modelMulti.compile(loss='mse',\n",
        "                   optimizer='adam',\n",
        "                   metrics='mse')\n",
        "modelMulti.summary()\n",
        "\n",
        "historyMulti = modelMulti.fit(X1_train, y1_train,\n",
        "                          validation_data=(X1_val,y1_val),\n",
        "                          callbacks=[cpMulti],\n",
        "                          epochs=50)\n",
        "\n",
        "#calling back the best model from the checkpoint\n",
        "modelMulti = load_model('modelMulti/')\n",
        "\n",
        "\n",
        "'''Loss Plots'''\n",
        "lossMulti = historyMulti.history['loss']\n",
        "val_lossMulti = historyMulti.history['val_loss']\n",
        "epochs = range(1,len(lossMulti)+1)\n",
        "plt.figure(figsize=(10,6),dpi=500)\n",
        "plt.plot(epochs,lossMulti, 'y', label='Training loss',linewidth=2)\n",
        "plt.plot(epochs,val_lossMulti, 'r', label='Validation loss',linewidth=2)\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Mean Squared Error')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t-4-mESZFdq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# LSTM Inclination Model\n",
        "# =============================================================================\n",
        "\n",
        "\n",
        "#Inclination Prediction Model\n",
        "ModelS = Sequential()\n",
        "\n",
        "\n",
        "ModelS.add(LSTM(512,#batch_input_shape=(5,30,1),\n",
        "                input_shape=(100,1),\n",
        "                stateful=False,name=\"LSTM1\"))\n",
        "#ModelS.add(Dropout(0.05,name=\"DROP2\"))\n",
        "\n",
        "ModelS.add(Dense(128, activation='relu',name=\"DENSE1\"))\n",
        "ModelS.add(Dropout(0.05,name=\"DROP1\"))\n",
        "\n",
        "ModelS.add(Dense(1,name=\"DENSE2\"))\n",
        "\n",
        "ModelS.summary()\n",
        "\n",
        "#creating a checkpoint when the best validation loss is found\n",
        "cpS = ModelCheckpoint('ModelS/', save_best_only=True)\n",
        "\n",
        "ModelS.compile (loss='mse',\n",
        "                optimizer='adam',\n",
        "                metrics='mse')\n",
        "\n",
        "historyInc = ModelS.fit(X2_train,y2_train,#batch_size=5,\n",
        "                        callbacks=[cpS],\n",
        "                        validation_data=(X2_val,y2_val),\n",
        "                        epochs=50)\n",
        "\n",
        "#Calling the Best Performing Model\n",
        "ModelS = load_model('ModelS/')\n",
        "\n",
        "''' Loss Plots '''\n",
        "lossInc = historyInc.history['loss']\n",
        "val_lossInc = historyInc.history['val_loss']\n",
        "epochs = range(1,len(lossInc)+1)\n",
        "font = {'family':'times new roman',\n",
        "        'weight':'normal',\n",
        "        'size':15}\n",
        "plt.rc('font', **font)\n",
        "plt.figure(figsize=(10,6),dpi=500)\n",
        "plt.plot(epochs,lossInc, 'y', label='Training loss',linewidth=2)\n",
        "plt.plot(epochs,val_lossInc, 'r', label='Validation loss',linewidth=2)\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Mean Squared Error')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XO3-ZlmDFiQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Predictions Of the Multi Target Model\n",
        "# =============================================================================\n",
        "\n",
        "Train_Prediction_1 = modelMulti.predict(X1_train)\n",
        "Val_Prediction_1 = modelMulti.predict(X1_val)\n",
        "\n",
        "Test_Prediction_1 = modelMulti.predict(X1_test)\n",
        "\n",
        "mseROP = mean_squared_error(y1_test.iloc[:,0], Test_Prediction_1[:,0])\n",
        "maeROP = mean_absolute_error(y1_test.iloc[:,0], Test_Prediction_1[:,0])\n",
        "\n",
        "mseINC = mean_squared_error(y1_test.iloc[:,1], Test_Prediction_1[:,1])\n",
        "maeINC = mean_absolute_error(y1_test.iloc[:,1], Test_Prediction_1[:,1])\n",
        "\n",
        "plt.plot(y1_test.values)\n",
        "plt.plot(Test_Prediction_1)"
      ],
      "metadata": {
        "id": "B0ohSL4KFrj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Predictions of the LSTM Model\n",
        "# =============================================================================\n",
        "\n",
        "Train_Prediction_2 = ModelS.predict(X2_train)\n",
        "Val_Prediction_2 = ModelS.predict(X2_val)\n",
        "\n",
        "Test_Prediction_2 = ModelS.predict(X2_test)\n",
        "\n",
        "mseS = mean_squared_error(y2_test, Test_Prediction_2)\n",
        "maeS = mean_absolute_error(y2_test, Test_Prediction_2)\n",
        "\n",
        "plt.plot(y2_test.values)\n",
        "plt.plot(Test_Prediction_2)"
      ],
      "metadata": {
        "id": "iieVdYOMFw3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# LSTM and MLP Model Merging\n",
        "# =============================================================================\n",
        "\n",
        "OutMLP = modelMulti.output\n",
        "OutLSTM = ModelS.output\n",
        "\n",
        "concatenated_output = Concatenate(name='concatenated_output')([OutMLP ,OutLSTM])\n",
        "\n",
        "dense_layer1 = Dense(1024, activation='relu')(concatenated_output)\n",
        "\n",
        "dense_layer2 = Dense(128, activation='relu')(dense_layer1)\n",
        "\n",
        "final_output = Dense(2, activation='linear')(dense_layer2)\n",
        "\n",
        "combined_model = Model(inputs=[modelMulti.input,ModelS.input],\n",
        "                       outputs=final_output)\n",
        "\n",
        "cpAll = ModelCheckpoint('combined_model/', save_best_only=True)\n",
        "\n",
        "combined_model.compile(loss='mse', optimizer='adam')\n",
        "\n",
        "combined_model.summary()\n",
        "\n",
        "#keras.utils.plot_model(combined_model,show_shapes=False,\n",
        "#                       show_layer_names=False,dpi=100)\n",
        "\n",
        "\n",
        "historyAll = combined_model.fit([X1_train, X2_train],y_train,\n",
        "                                validation_data=([X1_val,X2_val],y_val),\n",
        "                                callbacks=[cpAll],\n",
        "                                epochs=10)\n",
        "\n",
        "'''\n",
        "# First Concatenation\n",
        "\n",
        "outS = Reshape((1,))(modelMulti.output[:,1])\n",
        "outROP = Reshape((1,))(modelMulti.output[:,0])\n",
        "\n",
        "concatenated_output1 = Concatenate(name='concatenated_output')([outS, ModelS.output])\n",
        "\n",
        "dense_layer1 = Dense(1024, activation='relu')(concatenated_output1)\n",
        "final_output1 = Dense(1, activation='linear')(dense_layer1)\n",
        "\n",
        "combined_model_S = Model(inputs=[modelMulti.input,ModelS.input],\n",
        "                       outputs=final_output1)\n",
        "\n",
        "combined_model_S.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "combined_model_S.summary()\n",
        "\n",
        "\n",
        "# Second Concatenation\n",
        "\n",
        "concatenated_output2 = Concatenate(name='concatenated_output2')([outROP, combined_model_S.output])\n",
        "\n",
        "final_output2 = Dense(2, activation='linear')(concatenated_output2)\n",
        "\n",
        "combined_model_All = Model(inputs=[modelMulti.input,ModelS.input],\n",
        "                           outputs=final_output2)\n",
        "\n",
        "cpAll = ModelCheckpoint('combined_model_All/', save_best_only=True)\n",
        "\n",
        "combined_model_All.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "combined_model_All.summary()\n",
        "\n",
        "\n",
        "#keras.utils.plot_model(combined_model_All,show_shapes=False,\n",
        "#                       show_layer_names=False,dpi=100)\n",
        "\n",
        "\n",
        "historyAll = combined_model_All.fit([X1_train, X2_train],\n",
        "                                    y1_train,\n",
        "                                    validation_data=([X1_val,X2_val],y1_val),\n",
        "                                    callbacks=[cpAll],\n",
        "                                    epochs=100)\n",
        "'''\n",
        "\n",
        "\n",
        "''' Loss Plots '''\n",
        "lossAll = historyAll.history['loss']\n",
        "val_lossAll = historyAll.history['val_loss']\n",
        "epochs = range(1,len(lossAll)+1)\n",
        "font = {'family':'times new roman',\n",
        "        'weight':'normal',\n",
        "        'size':15}\n",
        "plt.rc('font', **font)\n",
        "plt.figure(figsize=(10,6),dpi=500)\n",
        "plt.plot(epochs,lossAll, 'y', label='Training loss',linewidth=2)\n",
        "plt.plot(epochs,val_lossAll, 'r', label='Validation loss',linewidth=2)\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Mean Squared Error')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "combined_model = load_model('combined_model/')"
      ],
      "metadata": {
        "id": "25COrwvFF56f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Tests\n",
        "# =============================================================================\n",
        "\n",
        "Train_Prediction = combined_model.predict([X1_train,X2_train])\n",
        "Val_Prediction = combined_model.predict([X1_val,X2_val])\n",
        "\n",
        "Test_Prediction = combined_model.predict([X1_test,X2_test])\n",
        "\n",
        "\n",
        "mseROP = mean_squared_error(y_test.iloc[:,0], Test_Prediction[:,0])\n",
        "maeROP = mean_absolute_error(y_test.iloc[:,0], Test_Prediction[:,0])\n",
        "\n",
        "mseINC = mean_squared_error(y_test.iloc[:,1], Test_Prediction[:,1])\n",
        "maeINC = mean_absolute_error(y_test.iloc[:,1], Test_Prediction[:,1])\n",
        "\n",
        "plt.plot(y2_test.values)\n",
        "plt.plot(Test_Prediction[:,1])"
      ],
      "metadata": {
        "id": "043uxWzDF81j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Preparing Data For Plots\n",
        "# =============================================================================\n",
        "\n",
        "RealIndex = np.arange(start=500,stop=845,step=0.05)\n",
        "trainIndex = np.arange(start=500,stop=780,step=0.05)\n",
        "valIndex = np.arange(start=780,stop=820,step=0.05)\n",
        "testIndex = np.arange(start=820,stop=845,step=0.05)\n",
        "\n",
        "IncReal = InclinationData[500:844]\n",
        "IncReal = IncReal.reset_index()\n",
        "IncReal = IncReal.iloc[:,1]\n",
        "\n",
        "\n",
        "IncReal = pd.DataFrame(data={'index':RealIndex,\n",
        "                              'Real Inclination':IncReal})\n",
        "IncReal.set_index('index',inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "train_results_ROP = pd.DataFrame(data={'index':trainIndex,\n",
        "                                       'Train Predictions ROP':Train_Prediction[:,0],\n",
        "                                       'Actual ROP':y1_train})\n",
        "train_results_ROP.set_index('index',inplace=True)\n",
        "\n",
        "train_results_Inc = pd.DataFrame(data={'index':trainIndex,\n",
        "                                   'Train Predictions Inclination':Train_Prediction[:,1],\n",
        "                                   'Actual inclination':y2_train})\n",
        "train_results_Inc.set_index('index',inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "val_results_ROP = pd.DataFrame(data={'index':valIndex,\n",
        "                                   'Validation Predictions ROP':Val_Prediction[:,0],\n",
        "                                   'Actual ROP':y1_val})\n",
        "val_results_ROP.set_index('index',inplace=True)\n",
        "\n",
        "val_results_Inc = pd.DataFrame(data={'index':valIndex,\n",
        "                                   'Validation Predictions Inclination':Val_Prediction[:,1],\n",
        "                                   'Actual inclination':y2_val})\n",
        "val_results_Inc.set_index('index',inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "test_results_ROP = pd.DataFrame(data={'index':testIndex,\n",
        "                                   'Test Predictions ROP':Test_Prediction[:,0],\n",
        "                                   'Actual ROP':y1_test})\n",
        "test_results_ROP.set_index('index',inplace=True)\n",
        "\n",
        "test_results_Inc = pd.DataFrame(data={'index':testIndex,\n",
        "                                   'Test Predictions Inclination':Test_Prediction[:,1],\n",
        "                                   'Actual inclination':y2_test})\n",
        "test_results_Inc.set_index('index',inplace=True)"
      ],
      "metadata": {
        "id": "su-3alkSF91u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Plotting\n",
        "# =============================================================================\n",
        "\n",
        "font = {'family':'times new roman',\n",
        "        'weight':'normal',\n",
        "        'size':20}\n",
        "plt.rc('font', **font)\n",
        "\n",
        "\n",
        "# ROP Plot\n",
        "plt.figure(figsize=(10,6),dpi=500)\n",
        "plt.plot(RateOfPenetration,'black',linewidth=3,label='Real Inclination')\n",
        "#plt.plot(test_results_ROP.iloc[:,1],linewidth=3,label='Real Inclination')\n",
        "#plt.plot(test_results_ROP.iloc[:,0],linewidth=3,label='Predicted Inclination')\n",
        "#plt.plot(val_results_ROP.iloc[:,1],linewidth=3,label='Real Inclination')\n",
        "#plt.plot(val_results_ROP.iloc[:,0],linewidth=3,label='Predicted Inclination')\n",
        "plt.xlabel('Measured Depth (m)')\n",
        "plt.ylabel('Rate of Penetration (m/h)')\n",
        "plt.legend(['Rate of Penetration'])\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#Inclination Plot\n",
        "plt.figure(figsize=(10,6),dpi=500)\n",
        "plt.plot(Inclination,'black',linewidth=3,label='Real Inclination')\n",
        "#plt.plot(test_results_Inc.iloc[:,1],linewidth=3,label='Real Inclination')\n",
        "#plt.plot(test_results_Inc.iloc[:,0],linewidth=3,label='Predicted Inclination')\n",
        "#plt.plot(val_results_Inc.iloc[:,1],linewidth=3,label='Real Inclination')\n",
        "#plt.plot(val_results_Inc.iloc[:,0],linewidth=3,label='Predicted Inclination')\n",
        "plt.xlabel('Measured Depth (m)')\n",
        "plt.ylabel('Inclination (deg)')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# ROP Full Plot\n",
        "plt.figure(figsize=(10,6),dpi=500)\n",
        "plt.plot(RateOfPenetration,'black', label='Real ROP',linestyle='dashed',linewidth=3)\n",
        "#plt.plot(IncReal.iloc[:320,:], label='Real ROP',linewidth=3)\n",
        "plt.plot(train_results_ROP.iloc[:,0], label='Training Predcitions',linewidth=3)\n",
        "plt.plot(val_results_ROP.iloc[:,0],  label='Validation Prediction',linewidth=3)\n",
        "plt.plot(test_results_ROP.iloc[:,0],  label='Test Predictions',linewidth=3)\n",
        "plt.xlabel('Measured Depth (m)')\n",
        "plt.ylabel('Rate of Penetration (m/h)')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#Inclination Full Plot\n",
        "plt.figure(figsize=(10,6),dpi=500)\n",
        "plt.plot(IncReal,'black', label='Real Inclination',linestyle='dashed',linewidth=3)\n",
        "#plt.plot(IncReal.iloc[:320,:], label='Real Inclination',linewidth=3)\n",
        "plt.plot(train_results_Inc.iloc[:,0], label='Training Predcitions',linewidth=3)\n",
        "plt.plot(val_results_Inc.iloc[:,0],  label='Validation Prediction',linewidth=3)\n",
        "plt.plot(test_results_Inc.iloc[:,0],  label='Test Predictions',linewidth=3)\n",
        "plt.xlabel('Measured Depth (m)')\n",
        "plt.ylabel('Inclination (deg)')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HYemxyiIGAbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###############################################################################\n",
        "# =============================================================================\n",
        "# Model Looping for Training Dataset Increment\n",
        "# =============================================================================\n",
        "###############################################################################\n",
        "\n",
        "\n",
        "maeTestVecROP10 = []\n",
        "maeTestVecInc10 = []\n",
        "maeTest10 = []\n",
        "\n",
        "\n",
        "TrVec = []\n",
        "VaVec = []\n",
        "TsVec = []\n",
        "\n",
        "for i in range(100,281, 20):\n",
        "    Tr = i\n",
        "    Va = Tr + 40\n",
        "    Ts = Va + 25\n",
        "    TrVec.append(Tr)\n",
        "    VaVec.append(Va)\n",
        "    TsVec.append(Ts)\n",
        "\n",
        "    ''' DataSplit'''\n",
        "\n",
        "    X1_train, y1_train = X1[500:500+Tr-0.01], y1[500:500+Tr-0.01]\n",
        "    X1_val, y1_val = X1[500+Tr:500+Va-0.01], y1[500+Tr:500+Va-0.01]\n",
        "    X1_test, y1_test = X1[500+Va:500+Ts-1], y1[500+Va:500+Ts-1]\n",
        "\n",
        "    X2_train, y2_train = X2[500:500+Tr-0.01], y2[500:500+Tr-0.01]\n",
        "    X2_val, y2_val = X2[500+Tr:500+Va-0.01], y2[500+Tr:500+Va-0.01]\n",
        "    X2_test, y2_test = X2[500+Va:500+Ts-1], y2[500+Va:500+Ts-1]\n",
        "\n",
        "\n",
        "    ''' Prediction '''\n",
        "\n",
        "    #MLP\n",
        "    drop=0.05\n",
        "\n",
        "    modelMulti = Sequential ()\n",
        "\n",
        "    modelMulti.add(Dense(1024, input_dim=50, activation='relu'))\n",
        "    modelMulti.add(Dropout(drop))\n",
        "\n",
        "    modelMulti.add(Dense(1024, activation='relu'))\n",
        "    modelMulti.add(Dropout(drop))\n",
        "\n",
        "    modelMulti.add(Dense(1, activation='linear'))\n",
        "\n",
        "    modelMulti.compile(loss='mse', optimizer='adam')\n",
        "\n",
        "    #LSTM\n",
        "    ModelS = Sequential()\n",
        "\n",
        "\n",
        "    ModelS.add(LSTM(512,#batch_input_shape=(5,30,1),\n",
        "                    input_shape=(100,1),\n",
        "                    stateful=False,name=\"LSTM1\"))\n",
        "    #ModelS.add(Dropout(0.05,name=\"DROP2\"))\n",
        "\n",
        "    ModelS.add(Dense(128, activation='relu',name=\"DENSE1\"))\n",
        "    ModelS.add(Dropout(0.05,name=\"DROP1\"))\n",
        "\n",
        "    ModelS.add(Dense(1,activation='linear',name=\"DENSE2\"))\n",
        "\n",
        "    ModelS.compile (loss='mse', optimizer='adam')\n",
        "\n",
        "    OutMLP = modelMulti.output\n",
        "    OutLSTM = ModelS.output\n",
        "\n",
        "\n",
        "    #concatenated_output = Concatenate(name='concatenated_output')([OutMLP ,OutLSTM])\n",
        "\n",
        "    #dense_layer1 = Dense(1024, activation='relu')(concatenated_output)\n",
        "    #dense_layer2 = Dense(1024, activation='relu')(dense_layer1)\n",
        "\n",
        "    output_layerROP = Dense(1, name='output1')(modelMulti.output)\n",
        "    output_layerInc = Dense(1, name='output2')(ModelS.output)\n",
        "\n",
        "    #final_output = Dense(2, activation='linear')(dense_layer2)\n",
        "\n",
        "    combined_model = Model(inputs=[modelMulti.input,ModelS.input],\n",
        "                           outputs=[output_layerROP, output_layerInc])\n",
        "\n",
        "    #cpAll = ModelCheckpoint('combined_model/', save_best_only=True)\n",
        "\n",
        "    cpAll = ModelCheckpoint(filepath='combined_model/',\n",
        "                            monitor='val_output2_loss',\n",
        "                            save_best_only=True)\n",
        "\n",
        "    #combined_model.compile(loss={'output1': 'mse', 'output2': 'mse'},\n",
        "    #         loss_weights={'output1': 1, 'output2': 1})\n",
        "\n",
        "    combined_model.compile(loss='mse', optimizer='adam')\n",
        "\n",
        "    combined_model.summary()\n",
        "\n",
        "    #keras.utils.plot_model(combined_model,show_shapes=False,\n",
        "    #                       show_layer_names=False,dpi=100)\n",
        "\n",
        "    historyAll = combined_model.fit([X1_train, X2_train],[y1_train,y2_train],\n",
        "                                    validation_data=([X1_val,X2_val],[y1_val,y2_val]),\n",
        "                                    callbacks=[cpAll],\n",
        "                                    epochs=40)\n",
        "\n",
        "    combined_model = load_model('combined_model/')\n",
        "\n",
        "    Prediction = combined_model.predict([X1_test, X2_test])\n",
        "\n",
        "    maeROPTest = mean_absolute_error(y1_test, Prediction[0])\n",
        "    #mseROPTest = mean_squared_error(y1_test, Prediction[0])\n",
        "\n",
        "    maeIncTest = mean_absolute_error(y2_test, Prediction[1])\n",
        "    #mseIncTest = mean_squared_error(y2_test, Prediction[1])\n",
        "\n",
        "\n",
        "    Predicted_ROP = pd.DataFrame(data=Prediction[0])\n",
        "    Predicted_Inclination = pd.DataFrame(data=Prediction[1])\n",
        "    Prediction_Combined = pd.concat([Predicted_ROP,Predicted_Inclination],axis=1)\n",
        "    y_test = pd.concat([y1_test,y2_test],axis=1)\n",
        "    maeTest = mean_absolute_error(y_test, Prediction_Combined)\n",
        "\n",
        "\n",
        "    maeTestVecROP10.append(maeROPTest)\n",
        "    maeTestVecInc10.append(maeIncTest)\n",
        "    maeTest10.append(maeTest)\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        " plt.plot(y2_test.values)\n",
        " plt.plot(Prediction[1])\n",
        "\n",
        " plt.plot(y1_test.values)\n",
        " plt.plot(Prediction[0])\n",
        "\n",
        " plt.plot(Prediction[1])\n",
        " plt.plot(Prediction[0])"
      ],
      "metadata": {
        "id": "QKObdl6tGDDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Importing Results (statistics)\n",
        "# =============================================================================\n",
        "VaVecNp=np.array(VaVec)\n",
        "indx = VaVecNp+500\n",
        "\n",
        "maeTestVec10 = maeTestVec10.iloc[:,1]\n",
        "\n",
        "maeTestVecAll = pd.concat([maeTestVec1,\n",
        "                           maeTestVec2,\n",
        "                           maeTestVec3,\n",
        "                           maeTestVec4,\n",
        "                           maeTestVec5,\n",
        "                           maeTestVec6,\n",
        "                           maeTestVec7,\n",
        "                           maeTestVec8,\n",
        "                           maeTestVec9,\n",
        "                           maeTestVec10.\n",
        "                           VaVec,],axis=1)\n",
        "maeTestVecAll.index = indx\n",
        "maeTestVecAll_Mean = maeTestVecAll.mean(axis=1)\n",
        "maeTestVecAll_Mean_of_Mean = maeTestVecAll_Mean.mean(axis=0)\n",
        "maeTestVecAll_Mean_of_Mean = pd.DataFrame({'Total Mean':[maeTestVecAll_Mean_of_Mean]*10},index=indx)\n",
        "Best_of_10 = maeTestVecAll.mean(axis=1).min()\n",
        "\n",
        "\n",
        "maeTestVecIncAll = pd.concat([maeTestVecInc1,\n",
        "                              maeTestVecInc2,\n",
        "                              maeTestVecInc3,\n",
        "                              maeTestVecInc4,\n",
        "                              maeTestVecInc5,\n",
        "                              maeTestVecInc6,\n",
        "                              maeTestVecInc7,\n",
        "                              maeTestVecInc8,\n",
        "                              maeTestVecInc9,\n",
        "                              maeTestVecInc10],axis=1)\n",
        "maeTestVecIncAll.index = indx\n",
        "maeTestVecIncAll_Mean = maeTestVecIncAll.mean(axis=1)\n",
        "maeTestVecIncAll_Mean_of_Mean = maeTestVecIncAll_Mean.mean(axis=0)\n",
        "maeTestVecIncAll_Mean_of_Mean = pd.DataFrame({'Total Mean':[maeTestVecIncAll_Mean_of_Mean]*10},index=indx)\n",
        "Best_of_10_Inc = maeTestVecIncAll.mean(axis=0).min()\n",
        "\n",
        "\n",
        "maeTestVecROPAll = pd.concat([maeTestVecROP1,\n",
        "                              maeTestVecROP2,\n",
        "                              maeTestVecROP3,\n",
        "                              maeTestVecROP4,\n",
        "                              maeTestVecROP5,\n",
        "                              maeTestVecROP6,\n",
        "                              maeTestVecROP7,\n",
        "                              maeTestVecROP8,\n",
        "                              maeTestVecROP9,\n",
        "                              maeTestVecROP10],axis=1)\n",
        "maeTestVecROPAll.index = indx\n",
        "maeTestVecROPAll_Mean = maeTestVecROPAll.mean(axis=1)\n",
        "maeTestVecROPAll_Mean_of_Mean = maeTestVecROPAll_Mean.mean(axis=0)\n",
        "maeTestVecROPAll_Mean_of_Mean = pd.DataFrame({'Total Mean':[maeTestVecROPAll_Mean_of_Mean]*10},index=indx)\n",
        "Best_of_10_ROP = maeTestVecROPAll.mean(axis=0).min()"
      ],
      "metadata": {
        "id": "jYZVaGAVGK5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Statistics Plots\n",
        "# =============================================================================\n",
        "\n",
        "''' maeTestVecAll'''\n",
        "\n",
        "font = {'family':'times new roman',\n",
        "        'weight':'normal',\n",
        "        'size':20}\n",
        "plt.rc('font', **font)\n",
        "\n",
        "plt.figure(figsize=(10,6),dpi=500)\n",
        "plt.scatter(indx,maeTestVecAll.iloc[:,0:1],s=70)\n",
        "plt.scatter(indx,maeTestVecAll.iloc[:,1:2],s=70)\n",
        "plt.scatter(indx,maeTestVecAll.iloc[:,2:3],s=70)\n",
        "plt.scatter(indx,maeTestVecAll.iloc[:,3:4],s=70)\n",
        "plt.scatter(indx,maeTestVecAll.iloc[:,4:5],s=70)\n",
        "plt.scatter(indx,maeTestVecAll.iloc[:,5:6],s=70)\n",
        "plt.scatter(indx,maeTestVecAll.iloc[:,6:7],s=70)\n",
        "plt.scatter(indx,maeTestVecAll.iloc[:,7:8],s=70)\n",
        "plt.scatter(indx,maeTestVecAll.iloc[:,8:9],s=70)\n",
        "plt.scatter(indx,maeTestVecAll.iloc[:,9:],s=70)\n",
        "plt.plot(maeTestVecAll_Mean,'black',linewidth=5,label='Mean')\n",
        "plt.plot(maeTestVecAll_Mean_of_Mean,'black',linewidth=3,label='Total Mean',linestyle='dashed')\n",
        "plt.xlabel('Measured Depth (m)')\n",
        "plt.ylabel('MAE')\n",
        "plt.xticks([640,660,680,700,720,740,760,780,800,820])\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "''' maeTestVecIncAll'''\n",
        "\n",
        "font = {'family':'times new roman',\n",
        "        'weight':'normal',\n",
        "        'size':20}\n",
        "plt.rc('font', **font)\n",
        "plt.figure(figsize=(10,6),dpi=500)\n",
        "plt.scatter(indx,maeTestVecIncAll.iloc[:,0:1],s=70)\n",
        "plt.scatter(indx,maeTestVecIncAll.iloc[:,1:2],s=70)\n",
        "plt.scatter(indx,maeTestVecIncAll.iloc[:,2:3],s=70)\n",
        "plt.scatter(indx,maeTestVecIncAll.iloc[:,3:4],s=70)\n",
        "plt.scatter(indx,maeTestVecIncAll.iloc[:,4:5],s=70)\n",
        "plt.scatter(indx,maeTestVecIncAll.iloc[:,5:6],s=70)\n",
        "plt.scatter(indx,maeTestVecIncAll.iloc[:,6:7],s=70)\n",
        "plt.scatter(indx,maeTestVecIncAll.iloc[:,7:8],s=70)\n",
        "plt.scatter(indx,maeTestVecIncAll.iloc[:,8:9],s=70)\n",
        "plt.scatter(indx,maeTestVecIncAll.iloc[:,9:],s=70)\n",
        "plt.plot(maeTestVecIncAll_Mean,'black',linewidth=5,label='Mean')\n",
        "plt.plot(maeTestVecIncAll_Mean_of_Mean,'black',linewidth=3,label='Total Mean',linestyle='dashed')\n",
        "plt.xlabel('Measured Depth (m)')\n",
        "plt.ylabel('MAE')\n",
        "plt.xticks([640,660,680,700,720,740,760,780,800,820])\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "''' maeTestVecROPAll'''\n",
        "\n",
        "font = {'family':'times new roman',\n",
        "        'weight':'normal',\n",
        "        'size':20}\n",
        "plt.rc('font', **font)\n",
        "plt.figure(figsize=(10,6),dpi=500)\n",
        "plt.scatter(indx,maeTestVecROPAll.iloc[:,0:1],s=70)\n",
        "plt.scatter(indx,maeTestVecROPAll.iloc[:,1:2],s=70)\n",
        "plt.scatter(indx,maeTestVecROPAll.iloc[:,2:3],s=70)\n",
        "plt.scatter(indx,maeTestVecROPAll.iloc[:,3:4],s=70)\n",
        "plt.scatter(indx,maeTestVecROPAll.iloc[:,4:5],s=70)\n",
        "plt.scatter(indx,maeTestVecROPAll.iloc[:,5:6],s=70)\n",
        "plt.scatter(indx,maeTestVecROPAll.iloc[:,6:7],s=70)\n",
        "plt.scatter(indx,maeTestVecROPAll.iloc[:,7:8],s=70)\n",
        "plt.scatter(indx,maeTestVecROPAll.iloc[:,8:9],s=70)\n",
        "plt.scatter(indx,maeTestVecROPAll.iloc[:,9:],s=70)\n",
        "plt.plot(maeTestVecROPAll_Mean,'black',linewidth=5,label='Mean')\n",
        "plt.plot(maeTestVecROPAll_Mean_of_Mean,'black',linewidth=3,label='Total Mean',linestyle='dashed')\n",
        "plt.xlabel('Measured Depth (m)')\n",
        "plt.ylabel('MAE')\n",
        "plt.xticks([640,660,680,700,720,740,760,780,800,820])\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6ey7oPTeGPlG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Plotting\n",
        "# =============================================================================\n",
        "\n",
        "\n",
        "#Plotting DT Input\n",
        "WOB = FeaturesROP['Weight on Bit kkgf'][500:665]\n",
        "ARS = FeaturesROP['Average Rotary Speed rpm'][500:665]\n",
        "AST = FeaturesROP['Average Surface Torque kN.m'][500:665]\n",
        "\n",
        "font = {'family':'times new roman',\n",
        "        'weight':'normal',\n",
        "        'size':20}\n",
        "plt.rc('font', **font)\n",
        "fig,(ax1,ax2,ax3,ax4) = plt.subplots(4, sharex=True,figsize=(10,8),dpi=500,gridspec_kw={'height_ratios': [2,1,1,1]})\n",
        "ax1.plot(Inclination[:640],'black',label='Real Inclination',linewidth=3)\n",
        "ax1.legend()\n",
        "ax1.grid(axis=\"x\")\n",
        "ax2.plot (WOB,'black',linewidth=3,label='Weight on Bit [kkgf]')\n",
        "ax2.legend()\n",
        "ax2.grid(axis=\"x\")\n",
        "ax3.plot (ARS,'black',linewidth=3,label='Average Rotary Speed [rpm]')\n",
        "ax3.legend()\n",
        "ax3.grid(axis=\"x\")\n",
        "ax4.plot (AST,'black',linewidth=3,label='Average Surface Torque [kN.m]')\n",
        "ax4.legend()\n",
        "ax4.grid(axis=\"x\")\n",
        "plt.xlabel('Measured Depth (m)')\n",
        "#fig.suptitle('Digital Twin Inputs used for ROP Prediction')\n",
        "plt.xticks([500,525,550,575,600,625,650,665])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ENyl9qsJGR96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Comparison\n",
        "# =============================================================================\n",
        "\n",
        "import xgboost as xgb\n",
        "\n",
        "regressor = xgb.XGBRegressor(objective='reg:squarederror',\n",
        "                             early_stopping_rounds=100,\n",
        "                             n_estimators=1000,\n",
        "                             learning_rate=0.001,\n",
        "                             max_depth=3)\n",
        "\n",
        "# Train the model\n",
        "regressor.fit(X1_train, y1_train,eval_set=[(X1_val, y1_val)])\n",
        "\n",
        "y_pred = regressor.predict(X1_test)\n",
        "maeTestXGB = mean_absolute_error(y1_test, y_pred)"
      ],
      "metadata": {
        "id": "CLseku38GUqq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}